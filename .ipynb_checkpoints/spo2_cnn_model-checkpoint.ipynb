{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyojungyang/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 1, 1, 40)`, `kernel shape=(1, 25, 40, 6)`, `dilation_rate=[1 1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m valid_data\u001b[38;5;241m.\u001b[39mapply(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mignore_errors)\n\u001b[1;32m    128\u001b[0m valid_data_batched \u001b[38;5;241m=\u001b[39m valid_data_tf\u001b[38;5;241m.\u001b[39mshuffle(buffer_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m--> 130\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m history \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mfit(train_data_batched, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, validation_data \u001b[38;5;241m=\u001b[39m valid_data_batched)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory)\n",
      "Cell \u001b[0;32mIn[7], line 73\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization())\n\u001b[1;32m     72\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m40\u001b[39m)))\n\u001b[0;32m---> 73\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m50\u001b[39m, (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m), activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     76\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPool2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/models/sequential.py:122\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers\u001b[38;5;241m.\u001b[39mappend(layer)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/models/sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/models/sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/ops/operation_utils.py:221\u001b[0m, in \u001b[0;36mcompute_conv_output_shape\u001b[0;34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed output size would be negative. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    228\u001b[0m     output_spatial_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor((spatial_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m strides) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Computed output size would be negative. Received `inputs shape=(None, 1, 1, 40)`, `kernel shape=(1, 25, 40, 6)`, `dilation_rate=[1 1]`."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/Volumes/My Passport/data/segmented_data')\n",
    "def split_train_valid_test(data_labels, p_train, p_valid, p_test):\n",
    "    # find filenames that match the labels \n",
    "    non_apnea_files = data_labels[data_labels['label'] == 0]['file'].values.astype(str)\n",
    "    \n",
    "    hypopnea_files = data_labels[data_labels['label'] == 1]['file'].values.astype(str)\n",
    "    \n",
    "    apnea_files = data_labels[data_labels['label'] == 2]['file'].values.astype(str)\n",
    "    \n",
    "    mixed_apnea_files = data_labels[data_labels['label'] == 3]['file'].values.astype(str)\n",
    "\n",
    "    # find length of filenames \n",
    "    num_non_apnea = len(non_apnea_files)\n",
    "    num_hypopnea = len(hypopnea_files)\n",
    "    num_apnea = len(apnea_files)\n",
    "    num_mixed = len(mixed_apnea_files)\n",
    "    \n",
    "    # find length of train, valid, test for each label\n",
    "    num_non_apnea_train = int(p_train * num_non_apnea)\n",
    "    num_hypopnea_train = int(p_train * num_hypopnea)\n",
    "    num_apnea_train = int(p_train * num_apnea)\n",
    "    num_mixed_train = int(p_train * num_mixed)\n",
    "    \n",
    "    num_non_apnea_valid = int(p_valid * num_non_apnea)\n",
    "    num_hypopnea_valid = int(p_valid * num_hypopnea)\n",
    "    num_apnea_valid = int(p_valid * num_apnea)\n",
    "    num_mixed_valid = int(p_valid * num_mixed)\n",
    "        \n",
    "    # shuffle the filenames randomly\n",
    "    non_apnea_files = np.random.permutation(non_apnea_files)\n",
    "    hypopnea_files = np.random.permutation(hypopnea_files)\n",
    "    apnea_files = np.random.permutation(apnea_files)\n",
    "    mixed_apnea_files = np.random.permutation(mixed_apnea_files)\n",
    "    \n",
    "    # find training test filenames\n",
    "    training_files = np.concatenate([\n",
    "                        non_apnea_files[:num_non_apnea_train], \n",
    "                        hypopnea_files[:num_hypopnea_train],\n",
    "                        apnea_files[:num_apnea_train], \n",
    "                        mixed_apnea_files[:num_mixed_train]\n",
    "                     ])\n",
    "    \n",
    "    valid_files = np.concatenate([\n",
    "                    non_apnea_files[num_non_apnea_train : num_non_apnea_train + num_non_apnea_valid], \n",
    "                    hypopnea_files[num_hypopnea_train : num_hypopnea_train + num_hypopnea_valid],\n",
    "                    apnea_files[num_apnea_train : num_apnea_train + num_apnea_valid], \n",
    "                    mixed_apnea_files[num_mixed_train : num_mixed_train + num_mixed_valid]\n",
    "                  ])\n",
    "\n",
    "    test_files = np.concatenate([\n",
    "                    non_apnea_files[num_non_apnea_train + num_non_apnea_valid:], \n",
    "                    hypopnea_files[num_hypopnea_train + num_hypopnea_valid:],\n",
    "                    apnea_files[num_apnea_train + num_apnea_valid:], \n",
    "                    mixed_apnea_files[num_mixed_train + num_mixed_valid:]\n",
    "                 ])\n",
    "    \n",
    "    return training_files, valid_files, test_files\n",
    "\n",
    "\n",
    "def create_model(): \n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    # Input Layer - all inputs are dimensions (320,000, ) -> outputs (320,000, ) \n",
    "    cnn_model.add(tf.keras.layers.InputLayer(input_shape = (40,), dtype = 'float32'))\n",
    "    # Convert audio to mel spectrogram -> outputs (num_mel_bins = 80, 2501)\n",
    "    cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Reshape((1, 1, 40)))\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(6, (1,25), activation = 'relu'))\n",
    "\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(50, (1,10), activation = 'relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    cnn_model.add(tf.keras.layers.Conv2D(30, (1,15), activation = 'relu'))\n",
    "    cnn_model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "    cnn_model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "    cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(4, activation = 'softmax'))\n",
    "    cnn_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return cnn_model\n",
    "\n",
    "def _parse_data_spo2(proto):\n",
    "    audio_sample_rate = 8000\n",
    "    segment_time = 40 \n",
    "    keys_to_features = {\n",
    "        'label': tf.io.FixedLenFeature([1], tf.int64),\n",
    "        'audio': tf.io.FixedLenFeature([audio_sample_rate * segment_time], tf.float32), \n",
    "        'spo2': tf.io.FixedLenFeature([segment_time], tf.float32) \n",
    "    }\n",
    "    \n",
    "    # Parse the record\n",
    "    try: \n",
    "        parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "        \n",
    "        # Extract features\n",
    "        label = parsed_features['label']\n",
    "        audio = parsed_features['audio']\n",
    "        spo2 = parsed_features['spo2']\n",
    "    \n",
    "        return spo2, label \n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        return None\n",
    "    except Exception: \n",
    "        return None\n",
    "\n",
    "data_labels = pd.read_csv('segmented_data_labels.csv')\n",
    "\n",
    "train_files, valid_files, test_files = split_train_valid_test(data_labels, 0.7, 0.15, 0.15)\n",
    "train_files_random = np.random.choice(train_files, 1000, replace = False)\n",
    "valid_files_random = np.random.choice(valid_files, 100, replace = False)\n",
    "\n",
    "batch_size = 128\n",
    "train_data_tf = tf.data.TFRecordDataset(train_files_random)\n",
    "train_data = train_data_tf.map(_parse_data_spo2)\n",
    "train_data = train_data.apply(tf.data.Dataset.ignore_errors)\n",
    "train_data_batched = train_data.shuffle(buffer_size = 1000).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_data_tf = tf.data.TFRecordDataset(valid_files_random)\n",
    "valid_data = valid_data_tf.map(_parse_data_spo2)\n",
    "valid_data = valid_data.apply(tf.data.Dataset.ignore_errors)\n",
    "valid_data_batched = valid_data_tf.shuffle(buffer_size = 1000).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "cnn_model = create_model()\n",
    "history = cnn_model.fit(train_data_batched, epochs = 1, verbose = 1, validation_data = valid_data_batched)\n",
    "print(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
